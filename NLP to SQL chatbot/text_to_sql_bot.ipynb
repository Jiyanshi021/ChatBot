{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf4be9f-510f-4d97-b831-ce4b6347b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --upgrade --quiet langchain langchain-community langchain-openai faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc0ce9d-f78a-4c32-9a9a-30435d91e041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "092d7264-5a8b-4efa-9da8-7bce9b60030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out the below to opt-out of using LangSmith in this notebook. Not required.\n",
    "if not os.environ.get(\"LANGCHAIN_API_KEY\"):\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b843b8c-e776-40ee-9c64-d895a2dfe96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Antônio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c67f37d-7a39-4fa2-bfdb-1699a6e21dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805d7af7-79c9-4f91-be0a-c6b27405f6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f972ae2-b033-4c93-a1e7-75fecf549d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Brazil',), ('Germany',), ('Canada',), ('Norway',), ('Czech Republic',), ('Czech Republic',), ('Austria',), ('Belgium',), ('Denmark',), ('Brazil',), ('Brazil',), ('Brazil',), ('Brazil',), ('Canada',), ('Canada',), ('USA',), ('USA',), ('USA',), ('USA',), ('USA',), ('USA',), ('USA',), ('USA',), ('USA',), ('USA',), ('USA',), ('USA',), ('USA',), ('Canada',), ('Canada',), ('Canada',), ('Canada',), ('Canada',), ('Portugal',), ('Portugal',), ('Germany',), ('Germany',), ('Germany',), ('France',), ('France',), ('France',), ('France',), ('France',), ('Finland',), ('Hungary',), ('Ireland',), ('Italy',), ('Netherlands',), ('Poland',), ('Spain',), ('Sweden',), ('United Kingdom',), ('United Kingdom',), ('United Kingdom',), ('Australia',), ('Argentina',), ('Chile',), ('India',), ('India',)]\n"
     ]
    }
   ],
   "source": [
    "#to just execute the query and print the result. \n",
    "\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain_core.runnables import RunnableMap, RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "# Initialize the tools\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "\n",
    "# Helper function to extract the SQL query\n",
    "def extract_sql_query(output):\n",
    "    parts = output.split(\"SQLQuery: \")\n",
    "    if len(parts) > 1:\n",
    "        return parts[1].strip()\n",
    "    return \"\"\n",
    "\n",
    "# Define the pipeline\n",
    "chain = (\n",
    "    write_query  # Generate SQL query\n",
    "    | RunnableMap({\"query\": extract_sql_query})  # Extract query part\n",
    "    | execute_query  # Execute the query\n",
    ")\n",
    " \n",
    "\n",
    "# Invoke the pipeline\n",
    "response = chain.invoke({\"question\": \"Which country has the highest total sales?\"})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb9a9c71-60dc-45fb-b645-3d63861eb7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user question is: Find all albums for the artist 'AC/DC'.\n",
      "\n",
      "The SQL query provided is a correct solution to this problem. It first finds the ArtistId of the artist 'AC/DC' from the Artist table and then finds all albums with that ArtistId from the Album table. The result is a list of all albums by AC/DC, which in this case is [(1, 'For Those About To Rock We Salute You'), (4, 'Let There Be Rock')].\n"
     ]
    }
   ],
   "source": [
    "# execute query and get the result in form of natural language.\n",
    "\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from operator import itemgetter\n",
    "\n",
    "# Define the prompt template\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "# Create the query generation chain\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "\n",
    "# Helper function to extract SQL query from the chain output\n",
    "def extract_sql_query(query_with_text):\n",
    "    parts = query_with_text.split(\"SQLQuery: \")\n",
    "    if len(parts) > 1:\n",
    "        sql_query = parts[1].strip()  # Extract the SQL query\n",
    "        return sql_query  # Return the extracted query\n",
    "    return \"\"\n",
    "\n",
    "# Step 1: Generate the SQL query from the user question\n",
    "generated_query = write_query.invoke({\"question\": \"Find all albums for the artist 'AC/DC'\"})  # Store full response\n",
    "sql_query = extract_sql_query(generated_query)  # Extract only the SQL query\n",
    "\n",
    "# Step 2: Execute the extracted query\n",
    "query_result = execute_query.invoke({\"query\": sql_query})  # Execute the SQL query and get the result\n",
    "\n",
    "# Step 3: Build the answer prompt\n",
    "answer_data = {\n",
    "    \"question\": \"Find all albums for the artist 'AC/DC'\",\n",
    "    \"query\": sql_query,\n",
    "    \"result\": query_result\n",
    "}\n",
    "\n",
    "# Step 4: Format the answer prompt\n",
    "formatted_prompt = answer_prompt.format(**answer_data)  # Format the prompt with input data\n",
    "\n",
    "# Step 5: Use LLM to generate a response\n",
    "llm_response = llm.invoke(formatted_prompt)  # LLM output as an AIMessage\n",
    "\n",
    "# Step 6: Parse the LLM response explicitly\n",
    "response = StrOutputParser().invoke(llm_response.content)  # Use the content of the AIMessage\n",
    "\n",
    "# Output the final result\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b7277fd-9110-42cc-9e16-cfe4bd69a2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deepak/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "GroqError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGroqError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# LLM initialization\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_groq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatGroq\n\u001b[0;32m---> 15\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mChatGroq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama3-8b-8192\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Define tools\u001b[39;00m\n\u001b[1;32m     18\u001b[0m execute_query \u001b[38;5;241m=\u001b[39m QuerySQLDataBaseTool(db\u001b[38;5;241m=\u001b[39mdb)\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/langchain_core/load/serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/langchain_groq/chat_models.py:405\u001b[0m, in \u001b[0;36mChatGroq.validate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    403\u001b[0m sync_specific: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient:\n\u001b[0;32m--> 405\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mgroq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGroq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msync_specific\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n\u001b[1;32m    409\u001b[0m     async_specific: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_async_client}\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/groq/_client.py:89\u001b[0m, in \u001b[0;36mGroq.__init__\u001b[0;34m(self, api_key, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m     87\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGROQ_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GroqError(\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m     )\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mGroqError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableMap\n",
    "\n",
    "# Database connection\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "\n",
    "# LLM initialization\n",
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")\n",
    "\n",
    "# Define tools\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "\n",
    "# Prompt for final explanation\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "    Question: {question}\n",
    "    SQL Query: {query}\n",
    "    SQL Result: {result}\n",
    "    Answer: \"\"\"\n",
    ")\n",
    "\n",
    "# Helper function to extract the SQL query\n",
    "def extract_sql_query(query_with_text):\n",
    "    parts = query_with_text.split(\"SQLQuery: \")\n",
    "    if len(parts) > 1:\n",
    "        return parts[1].strip()\n",
    "    return \"\"\n",
    "\n",
    "# Main function for Gradio\n",
    "def process_question(user_question):\n",
    "    try:\n",
    "        # Step 1: Generate the SQL query from the user question\n",
    "        generated_query = write_query.invoke({\"question\": user_question})\n",
    "        sql_query = extract_sql_query(generated_query)  # Extract only the SQL query\n",
    "\n",
    "        # Step 2: Execute the extracted query\n",
    "        query_result = execute_query.invoke({\"query\": sql_query})  # Execute the SQL query and get the result\n",
    "\n",
    "        # Step 3: Build the answer prompt\n",
    "        answer_data = {\n",
    "            \"question\": user_question,\n",
    "            \"query\": sql_query,\n",
    "            \"result\": query_result\n",
    "        }\n",
    "\n",
    "        # Step 4: Format the answer prompt\n",
    "        formatted_prompt = answer_prompt.format(**answer_data)\n",
    "\n",
    "        # Step 5: Use LLM to generate a response\n",
    "        llm_response = llm.invoke(formatted_prompt)\n",
    "\n",
    "        # Step 6: Parse the LLM response explicitly\n",
    "        response = StrOutputParser().invoke(llm_response.content)\n",
    "\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "# Gradio Interface\n",
    "def main():\n",
    "    interface = gr.Interface(\n",
    "        fn=process_question,\n",
    "        inputs=gr.Textbox(label=\"Enter your question\", placeholder=\"E.g., Find all albums for the artist 'AC/DC'.\"),\n",
    "        outputs=gr.Textbox(label=\"Response\", placeholder=\"The extracted query and natural language explanation will appear here.\")\n",
    "    )\n",
    "\n",
    "    interface.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df0a85a-bdc7-4286-aa3f-863fddd04e32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
